{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pprint import pprint as pp\n",
    "from typing import Dict, List, Tuple\n",
    "\n",
    "import random\n",
    "import csv\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building Knowledge Graph"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract Data from CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_csv_data(filepath, handle_row_func):\n",
    "    data = dict()\n",
    "    with open(filepath) as file:\n",
    "        next(file)\n",
    "        rows = csv.reader(file, delimiter=\",\")\n",
    "        for row in rows:\n",
    "            handle_row_func(data, row)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def handle_csv_kanji_func(data, row):\n",
    "    kanji,*meanings = row\n",
    "    if len(meanings) >= 2:\n",
    "        meanings = \",\".join(meanings)\n",
    "    else:\n",
    "        meanings = meanings[0]\n",
    "    meanings = meanings.split(\":\")\n",
    "    meanings = meanings[0]\n",
    "    data[kanji] = meanings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data_kanji = get_csv_data(\"dataset/s5_kanjis_output.csv\", handle_csv_kanji_func)\n",
    "print(\"len(data_kanji) = \", len(data_kanji))\n",
    "# pp(data_kanji)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def handle_csv_radical_func(data, row):\n",
    "    radical,meaning,_ = row\n",
    "    data[radical] = meaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_radical = get_csv_data(\"dataset/s7_nodes_radical_meaning.csv\", handle_csv_radical_func)\n",
    "print(\"len(data_radical) = \", len(data_radical))\n",
    "# pp(data_radical)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def handle_csv_edges_func(data, row):\n",
    "    kanji,radical_list = row\n",
    "    data[kanji] = radical_list.split(':')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_edges = get_csv_data(\"dataset/s7_edges_kanji_radical.csv\", handle_csv_edges_func)\n",
    "print(\"len(data_edges) = \", len(data_edges))\n",
    "# pp(data_edges)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Structure"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Node Manager"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_key(symbol, dtype):\n",
    "    return f\"{symbol}-{dtype}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "node_kanji = {\n",
    "    get_key(symbol, 'kanji'): {\n",
    "        'symbol' : symbol,\n",
    "        'meaning': meaning,\n",
    "        'visual' : f\"{symbol}\\n{meaning}\",\n",
    "        'color'  : 'red',\n",
    "    } for symbol, meaning in data_kanji.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "node_radical = {\n",
    "    get_key(symbol, 'radical'): {\n",
    "        'symbol' : symbol,\n",
    "        'meaning': meaning,\n",
    "        'visual' : f\"{symbol}\\n{meaning}\",\n",
    "        'color'  : 'yellow',\n",
    "    } for symbol, meaning in data_radical.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_node = {**node_radical, **node_kanji}\n",
    "# pp(list(full_node.keys()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Edge Manager"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_graph_edge(data_edges):\n",
    "    edges = []\n",
    "    for kanji, radicals in data_edges.items():\n",
    "        for r in radicals:\n",
    "            edges.append( (f\"{kanji}-kanji\", f\"{r}-radical\") )\n",
    "    return edges\n",
    "\n",
    "full_edges = get_graph_edge(data_edges)\n",
    "# full_edges"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "G = nx.Graph()\n",
    "\n",
    "G.add_nodes_from(full_node.items())\n",
    "G.add_edges_from(full_edges)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Graph Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import matplotlib.font_manager as fm\n",
    "\n",
    "# Reference: https://albertauyeung.github.io/2020/03/15/matplotlib-cjk-fonts.html\n",
    "[f for f in fm.fontManager.ttflist if 'CJK JP' in f.name]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_graph(\n",
    "    Graph: nx.Graph, \n",
    "    figsize: tuple=(7,7), \n",
    "    color_map: List[str]=None, \n",
    "    node_size: int=3000, \n",
    "    with_labels: bool=True) -> None:\n",
    "    \n",
    "    if color_map == None:\n",
    "        color_map = [Graph.nodes[n][\"color\"] for n in Graph] \n",
    "    else:\n",
    "        color_map = color_map\n",
    "    \n",
    "    plt.figure(1,figsize=figsize) \n",
    "    \n",
    "    labels = nx.get_node_attributes(Graph, 'visual')\n",
    "    \n",
    "    nx.draw_kamada_kawai(Graph, \n",
    "                         node_color=color_map, \n",
    "                         with_labels=with_labels,\n",
    "                         labels=labels,\n",
    "                         node_size=node_size, \n",
    "                         font_size=20,\n",
    "                         font_family=\"Noto Serif CJK JP\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_graph(\n",
    "    Graph       = G.subgraph(random.sample(G.nodes, 300)),\n",
    "    node_size   = 100,\n",
    "    with_labels = None,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sg_kanji_with() -> nx.Graph:\n",
    "    sg = nx.Graph()\n",
    "    p = '痘-kanji'\n",
    "    radicals = [n for n in G.neighbors(p)]\n",
    "    sg.add_nodes_from([(p, G.nodes[p])] + [(r, G.nodes[r]) for r in radicals])\n",
    "    sg.add_edges_from([(p, rp) for rp in radicals])\n",
    "    return sg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_graph(\n",
    "    Graph       = get_sg_kanji_with(),\n",
    "    node_size   = 2000,\n",
    "    with_labels = True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(nx.info(G))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://networkx.org/documentation/stable/reference/algorithms/component.html\n",
    "\n",
    "print('number of connected components: ', nx.number_connected_components(G))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://networkx.org/documentation/stable/reference/algorithms/isolates.html\n",
    "# EDA + Preprocessing: Removing Isolated Nodes\n",
    "\n",
    "print('number of isolated: ', nx.number_of_isolates(G))\n",
    "isolated_nodes = [n for n in nx.isolates(G)]\n",
    "pp(isolated_nodes)\n",
    "G.remove_nodes_from(list(nx.isolates(G)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(nx.info(G))\n",
    "\n",
    "print('number of connected components: ', nx.number_connected_components(G))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_graph(\n",
    "    Graph       = G.subgraph(random.sample(G.nodes, 300)),\n",
    "    node_size   = 100,\n",
    "    with_labels = None,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Querying Knowledge Graph"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_graph(nodes: List) -> nx.Graph:\n",
    "    R = nx.Graph()\n",
    "    R.add_nodes_from([(n, G.nodes[n]) for n in nodes])\n",
    "    R.add_edges_from(nx.utils.pairwise(nodes))\n",
    "    return R"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_node_color_result(kinputs, koutputs, union_result):\n",
    "    G = union_result\n",
    "    color_map = []\n",
    "    for n in union_result:\n",
    "        if n in kinputs:\n",
    "            color_map.append(\"green\")\n",
    "        elif n in koutputs:\n",
    "            color_map.append(\"blue\")\n",
    "        else:\n",
    "            color_map.append(G.nodes[n][\"color\"])\n",
    "    return color_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kin = '語-kanji'  # say\n",
    "kout = '誕-kanji' # lie \n",
    "\n",
    "result_shortest_path = nx.shortest_path(G, source=kin, target=kout)\n",
    "result = generate_graph(result_shortest_path)\n",
    "\n",
    "visualize_graph(\n",
    "    Graph=result, \n",
    "    color_map=get_node_color_result([kin], [kout], result), \n",
    "    figsize=(6,6)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Brute Force Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_path_bf(G: nx.Graph, MOrig: List, MDest: List) -> nx.Graph:\n",
    "    \n",
    "    result = []\n",
    "    \n",
    "    for kin in MOrig:\n",
    "        for kout in MDest:\n",
    "            print(kin, kout)\n",
    "            sp_raw = nx.dijkstra_path(G, source=kin, target=kout)\n",
    "            sp_graph = generate_graph(sp_raw)\n",
    "            \n",
    "            result.append(sp_graph)\n",
    "    \n",
    "    \n",
    "    return nx.compose_all(result)        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Astar Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_path_astar(G: nx.Graph, MOrig: List, MDest: List, heuristic_func) -> nx.Graph:\n",
    "    \n",
    "    result = []\n",
    "    \n",
    "    for kin in MOrig:\n",
    "        for kout in MDest:\n",
    "            sp_raw = nx.astar_path(G, source=kin, target=kout, heuristic=heuristic_func)\n",
    "            sp_graph = generate_graph(sp_raw)\n",
    "            \n",
    "            result.append(sp_graph)\n",
    "    \n",
    "    \n",
    "    return nx.compose_all(result)        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Heuristic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def common_neighbor(u, v):\n",
    "    return len(list(nx.common_neighbors(G, u, v)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def jaccard_function(u, v):\n",
    "    union_size = len(set(G[u]) | set(G[v])) # union neighbor\n",
    "    if union_size == 0:\n",
    "        return 0\n",
    "    return len(list(nx.common_neighbors(G, u, v))) / union_size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Steiner Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "all_pairs_dijkstra = nx.all_pairs_dijkstra(G, weight='weight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def metric_closure(G, weight=\"weight\"):\n",
    "    M = nx.Graph()\n",
    "\n",
    "    Gnodes = set(G)\n",
    "\n",
    "    # check for connected graph while processing first node\n",
    "    all_paths_iter = all_pairs_dijkstra\n",
    "    u, (distance, path) = next(all_paths_iter)\n",
    "    if Gnodes - set(distance):\n",
    "        msg = \"G is not a connected graph. metric_closure is not defined.\"\n",
    "        raise nx.NetworkXError(msg)\n",
    "    Gnodes.remove(u)\n",
    "    for v in Gnodes:\n",
    "        M.add_edge(u, v, distance=distance[v], path=path[v])\n",
    "\n",
    "    # first node done -- now process the rest\n",
    "    for u, (distance, path) in all_paths_iter:\n",
    "        Gnodes.remove(u)\n",
    "        for v in Gnodes:\n",
    "            M.add_edge(u, v, distance=distance[v], path=path[v])\n",
    "\n",
    "    return M"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def steiner_tree(G, terminal_nodes, weight=\"weight\"):\n",
    "    # H is the subgraph induced by terminal_nodes in the metric closure M of G.\n",
    "    M = metric_closure(G, weight=weight)\n",
    "    H = M.subgraph(terminal_nodes)\n",
    "    # Use the 'distance' attribute of each edge provided by M.\n",
    "    mst_edges = nx.minimum_spanning_edges(H, weight=\"distance\", data=True)\n",
    "    # Create an iterator over each edge in each shortest path; repeats are okay\n",
    "    edges = chain.from_iterable(pairwise(d[\"path\"]) for u, v, d in mst_edges)\n",
    "    # For multigraph we should add the minimal weight edge keys\n",
    "    if G.is_multigraph():\n",
    "        edges = (\n",
    "            (u, v, min(G[u][v], key=lambda k: G[u][v][k][weight])) for u, v in edges\n",
    "        )\n",
    "    T = G.edge_subgraph(edges)\n",
    "    return T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_path_steiner(G: nx.Graph, MOrig: List, MDest: List) -> nx.Graph:\n",
    "    \n",
    "    return nx.steiner_tree(G, MOrig + MDest)     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# result = find_path_steiner(MOrig, MDest)\n",
    "# result.nodes()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from kanji_lists import JLPT, KYOIKU\n",
    "# https://github.com/ffe4/kanji-lists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_cases_raw = {\n",
    "    'N5 to N4': {\n",
    "        'MOrig': JLPT.N5,\n",
    "        'MDest': JLPT.N4,\n",
    "    },\n",
    "    'N4 to N3': {\n",
    "        'MOrig': JLPT.N4,\n",
    "        'MDest': JLPT.N3,\n",
    "    },\n",
    "    'N3 to N2': {\n",
    "        'MOrig': JLPT.N3,\n",
    "        'MDest': JLPT.N2,\n",
    "    },\n",
    "    'N2 to N1': {\n",
    "        'MOrig': JLPT.N2,\n",
    "        'MDest': JLPT.N1,\n",
    "    },\n",
    "    'G1 to G2': {\n",
    "        'MOrig': KYOIKU.GRADE1,\n",
    "        'MDest': KYOIKU.GRADE2,\n",
    "    },\n",
    "    'G2 to G3': {\n",
    "        'MOrig': KYOIKU.GRADE2,\n",
    "        'MDest': KYOIKU.GRADE3,\n",
    "    },\n",
    "    'G3 to G4': {\n",
    "        'MOrig': KYOIKU.GRADE3,\n",
    "        'MDest': KYOIKU.GRADE4,\n",
    "    },\n",
    "    'G4 to G5': {\n",
    "        'MOrig': KYOIKU.GRADE4,\n",
    "        'MDest': KYOIKU.GRADE5,\n",
    "    },\n",
    "    'G5 to G6': {\n",
    "        'MOrig': KYOIKU.GRADE5,\n",
    "        'MDest': KYOIKU.GRADE6,\n",
    "    },\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tc_filter_in_graph(kanji_list):\n",
    "    \n",
    "    tc_filtered = []\n",
    "    for k in kanji_list:\n",
    "\n",
    "        tk = get_key(k, 'kanji')\n",
    "        \n",
    "        if tk in G:\n",
    "            tc_filtered.append(tk)\n",
    "            continue\n",
    "        \n",
    "        tr = get_key(k, 'radical')\n",
    "        if tr in G:\n",
    "            tc_filtered.append(tr)\n",
    "            continue\n",
    "            \n",
    "    return tc_filtered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_test_cases_raw(test_cases_raw):\n",
    "    test_cases_clean = {}\n",
    "    for tc_name, tc in test_cases_raw.items():\n",
    "\n",
    "        MOrig = tc_filter_in_graph(tc['MOrig'])\n",
    "        MDest = tc_filter_in_graph(tc['MDest'])\n",
    "\n",
    "        test_cases_clean[tc_name] = {\n",
    "            'MOrig': MOrig,\n",
    "            'MDest': MDest,\n",
    "        }\n",
    "\n",
    "    return test_cases_clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_cases_clean = filter_test_cases_raw(test_cases_raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_path(G: nx.Graph, MOrig: List, MDest: List, method='brute_force') -> nx.Graph:\n",
    "    if method == 'brute_force':\n",
    "        return find_path_bf(G, MOrig, MDest)\n",
    "    elif method == 'steiner_tree':\n",
    "        return find_path_steiner(G, MOrig, MDest)\n",
    "    elif method == 'astar_common_neighbor':\n",
    "        return find_path_astar(G, MOrig, MDest, common_neighbor)\n",
    "    elif method == 'astar_jaccard':\n",
    "        return find_path_astar(G, MOrig, MDest, jaccard_function)\n",
    "    elif method == 'astar_0':\n",
    "        return find_path_astar(G, MOrig, MDest, lambda x, y: 0)\n",
    "    else:\n",
    "        raise ValueError(f\"method {method} is not valid\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_result_accuracy(G0, Gt):\n",
    "    common_nodes = len(G0.nodes() & Gt.nodes())\n",
    "    G0_nodes     = len(G0.nodes())\n",
    "    \n",
    "    return common_nodes / G0_nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_results_kanjigen(G: nx.Graph, algo_list: List, test_cases_clean: dict):\n",
    "    results = {tc_name: dict() for tc_name in test_cases_clean}\n",
    "\n",
    "    for tc_name, tc in test_cases_clean.items():\n",
    "        \n",
    "        if tc_name != 'N5 to N4':\n",
    "            continue\n",
    "        \n",
    "        MOrig = tc['MOrig'][:3]\n",
    "        MDest = tc['MDest'][:3]\n",
    "        \n",
    "        # get time\n",
    "        for algo in algo_list:\n",
    "            \n",
    "            print(f\"algo: {algo}\")\n",
    "            print(f\"tc: {tc_name} of {len(test_cases_clean)}\")\n",
    "            start  = time.time()\n",
    "            graph  = find_path(G, MOrig, MDest, algo)\n",
    "            end    = time.time()\n",
    "            print(\"finish\")\n",
    "            print(\"==============\")\n",
    "            \n",
    "            results[tc_name][algo] = {'graph': graph, 'time': (end - start)}\n",
    "        \n",
    "        # get accuracy\n",
    "        \n",
    "        G0 = results[tc_name]['brute_force']['graph']\n",
    "        for algo in [algo for algo in algo_list if algo != 'brute_force']:\n",
    "            \n",
    "            Gt = results[tc_name][algo]['graph']\n",
    "            \n",
    "            results[tc_name][algo][\"accuracy\"] = get_result_accuracy(G0, Gt)\n",
    "    \n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "algo_list = ['brute_force', 'astar_common_neighbor', 'astar_jaccard', 'astar_0']\n",
    "results = get_results_kanjigen(G, algo_list, test_cases_clean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pp(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'pandas' from '/home/ifkarsyah/Documents/ITB/kanjigen/kanjigen-be/venv/lib/python3.8/site-packages/pandas/__init__.py'>"
      ]
     },
     "execution_count": 189,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "196.75px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
